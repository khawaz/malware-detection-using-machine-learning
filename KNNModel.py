import pandas
import numpy
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn import preprocessing
from sklearn.model_selection import cross_val_score


file = pandas.read_csv("TrainingData.csv")


features = file.drop("legitimate", axis=1)
labels = file["legitimate"]


features = numpy.array(features).reshape(-1,8)
labels = numpy.array(labels)

features = preprocessing.MinMaxScaler().fit_transform(features)

X_train , X_test, Y_train, Y_test = train_test_split(features,labels,test_size=0.3,random_state=0)

model = KNeighborsClassifier(n_neighbors=6)
model.fit(X_train,Y_train)
predictions = model.predict(X_test)


# cross_valid_scores = []
#
#
# # the output was 6
# for k in range(1,1000):
#     knn = KNeighborsClassifier(n_neighbors=k)
#     scores = cross_val_score(knn,features,labels, cv=5, scoring='accuracy')
#     cross_valid_scores.append(scores.mean())
#
#
# print("Optimal K with cross-validation : ",np.argmax(cross_valid_scores))

print(confusion_matrix(Y_test,predictions))
print(accuracy_score(Y_test,predictions))


import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

fpr, tpr , threshold = roc_curve(Y_test,predictions)
aucScore = auc(fpr,tpr)

plt.figure(figsize=(5,5), dpi=100)
plt.plot(fpr,tpr,linestyle = "-",label = "KNN (auc = %0.3f)" % aucScore)
plt.xlabel('False Positive Rate -->')
plt.ylabel("True Positive Rate -->")

plt.legend()
plt.show()

print(fpr)
print(tpr)
print(threshold)
print(aucScore)



import pickle


pickle.dump(model, open('models/KNNModel.pkl', 'wb'))

model = pickle.load(open('models/KNNModel.pkl', 'rb'))
